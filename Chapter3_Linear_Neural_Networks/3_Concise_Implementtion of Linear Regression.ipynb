{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "import sys\nsys.path.append(\"../\")\n\nfrom mxnet import  nd, gluon, autograd\nfrom d2l import linear_regression as lr\nfrom mxnet.gluon import nn\nfrom mxnet import init\nfrom mxnet.gluon import loss as gloss\n"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [],
      "source": "\u0027\u0027\u0027\n    1. Generating Data Sets\n\u0027\u0027\u0027\n\ntrue_w  \u003d nd.array([2, -3.4])\ntrue_b \u003d  4.2\n\nfeatures, labels \u003d lr.synthetic_data(true_w, true_b, 1000)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "\n[[-0.676097    0.9117826 ]\n [-0.62421465 -0.8773768 ]\n [-0.30135608 -0.0841791 ]\n [-1.8832594   1.5562055 ]\n [-0.04205222 -2.3422642 ]\n [ 0.05762542 -0.10484769]\n [-0.2864682   0.59069526]\n [-0.30959353  1.3222921 ]\n [ 0.18612005  0.60621804]\n [-1.5594455  -0.70880044]]\n\u003cNDArray 10x2 @cpu(0)\u003e \n[-0.30947077  5.8963757   3.9195411  -4.5920196  12.195138    4.611757\n  1.5967504  -0.90867716  2.7529073   3.5207562 ]\n\u003cNDArray 10 @cpu(0)\u003e\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "\u0027\u0027\u0027\n    2. Reading Data\n\u0027\u0027\u0027\ndef load_array(data_arrays, batch_size, is_train \u003d True):\n    dataset \u003d  gluon.data.ArrayDataset(*data_arrays)\n    return gluon.data.DataLoader(dataset, batch_size, shuffle \u003d is_train)\n\nbatch_size \u003d 10\ndata_iter \u003d  load_array((features, labels), batch_size)\n\nfor X, y in data_iter:\n    print(X, y)\n    break",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "outputs": [],
      "source": "\u0027\u0027\u0027\n    3. Define the Model\n\u0027\u0027\u0027\n# We don\u0027t have to tell Gluon how may inputs go into this linear layer, Gluon will infer the number of inputs to each layer automatically\nnet \u003d nn.Sequential()\n# We only want to generate a single scalar\nnet.add(nn.Dense(1))\n\n#Initialize Model Parameters\nnet.initialize(init.Normal(sigma\u003d 0.01))\n#Define the loss function\nloss \u003d gloss.L2Loss()\n\ntrainer \u003d gluon.Trainer(net.collect_params(), \"sgd\", {\"learning_rate\" : 0.03})\n\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "epoch 1 loss: 0.050262\nepoch 2 loss: 0.005354\nepoch 3 loss: 0.005234\nError in estimating w \n[[-0.00632286  0.00204611]]\n\u003cNDArray 1x2 @cpu(0)\u003e\nError in estimating b \n[-0.00538397]\n\u003cNDArray 1 @cpu(0)\u003e\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "\u0027\u0027\u0027\n    4. Training\n\u0027\u0027\u0027\nnum_epochs \u003d 3\nfor epoch in range(1, num_epochs + 1):\n    for X, y in data_iter:\n        with autograd.record():\n            # If we replace l \u003d loss(output, y) with l \u003d loss(output, y).mean(), we need to change trainer.step(batch_size) to trainer.step(1) accordingly. Why?\n            l \u003d loss(net(X), y)\n        l.backward()\n        trainer.step(batch_size)\n    l \u003d  loss(net(features), labels)\n    print(\"epoch %d loss: %f\" % (epoch, l.mean().asnumpy()))\n    \nw \u003d net[0].weight.data()\nb \u003d net[0].bias.data()\n\nprint(\"Error in estimating w\", true_w.reshape(w.shape) - w)\nprint(\"Error in estimating b\", true_b - b)\n            ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": "\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}